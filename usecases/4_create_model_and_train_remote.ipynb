{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079489b9-1eac-4dfc-891a-8aa7fa8b0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import  time\n",
    "import random\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64719a2d-7339-46d6-996a-3bc25b7292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 128\n",
    "im_height = 128\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "num_class = 2\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_unet(input_img, n_filters = 64, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(num_class, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "\n",
    "def TV_bin_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    bin_loss = binary_crossentropy(y_true_f, y_pred_f)\n",
    "    images = y_pred[: : ,: ,1]\n",
    "    value = tf.reduce_mean(tf.abs(images[:,1:,:] - images[:,:-1,:])) + tf.reduce_mean(tf.abs(images[:,:,1:] - images[:,:,:-1]))\n",
    "    return 2.4e-7*value + bin_loss\n",
    "\n",
    "\n",
    "def dice_coef(y_pred, y_true):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    layer_names=[layer.name for layer in model.layers]\n",
    "    for l in layer_names:\n",
    "        if l==layer_names[-1]:\n",
    "            value = TV_bin_loss(y_true, y_pred)\n",
    "        else:\n",
    "            value = binary_crossentropy(K.flatten(y_true),K.flatten(y_pred))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d72c01-7c5d-43eb-a72b-19a537a395cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = h5py.File(\"h5_datasets/combined_CT_datasets.h5\", \"r\")\n",
    "\n",
    "X_train = np.array(combined_data[\"X_train\"])\n",
    "X_valid = np.array(combined_data[\"X_valid\"])\n",
    "y_train = np.array(combined_data[\"y_train\"])\n",
    "y_valid = np.array(combined_data[\"y_valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d66b655e-30d8-4cf8-9fd6-24f424a3dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 15:34:58.513266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:58.547855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:58.548428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:58.550208: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-15 15:34:58.552448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:58.553030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:58.553502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:59.284899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:59.285232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:59.285506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-15 15:34:59.285734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13793 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 15:35:07.063662: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-02-15 15:35:07.708222: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.9377 - dice_loss: 0.2527 - recall_1: 0.8949 - pre_1: 0.9428\n",
      "Epoch 00001: val_loss improved from inf to 7.27577, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 50s 838ms/step - loss: 0.3144 - accuracy: 0.9377 - dice_loss: 0.2527 - recall_1: 0.8949 - pre_1: 0.9428 - val_loss: 7.2758 - val_accuracy: 0.5515 - val_dice_loss: 0.4715 - val_recall_1: 0.5319 - val_pre_1: 0.5252 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.9654 - dice_loss: 0.1181 - recall_1: 0.9635 - pre_1: 0.9667\n",
      "Epoch 00002: val_loss improved from 7.27577 to 0.62419, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 22s 537ms/step - loss: 0.1487 - accuracy: 0.9654 - dice_loss: 0.1181 - recall_1: 0.9635 - pre_1: 0.9667 - val_loss: 0.6242 - val_accuracy: 0.9592 - val_dice_loss: 0.0397 - val_recall_1: 0.9592 - val_pre_1: 0.9592 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9774 - dice_loss: 0.0785 - recall_1: 0.9764 - pre_1: 0.9780\n",
      "Epoch 00003: val_loss did not improve from 0.62419\n",
      "41/41 [==============================] - 21s 520ms/step - loss: 0.1005 - accuracy: 0.9774 - dice_loss: 0.0785 - recall_1: 0.9764 - pre_1: 0.9780 - val_loss: 0.7299 - val_accuracy: 0.9468 - val_dice_loss: 0.1282 - val_recall_1: 0.8736 - val_pre_1: 0.9652 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.9798 - dice_loss: 0.0577 - recall_1: 0.9797 - pre_1: 0.9798\n",
      "Epoch 00004: val_loss improved from 0.62419 to 0.18474, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 23s 550ms/step - loss: 0.0790 - accuracy: 0.9798 - dice_loss: 0.0577 - recall_1: 0.9797 - pre_1: 0.9798 - val_loss: 0.1847 - val_accuracy: 0.9418 - val_dice_loss: 0.1075 - val_recall_1: 0.9285 - val_pre_1: 0.9407 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9821 - dice_loss: 0.0452 - recall_1: 0.9819 - pre_1: 0.9821\n",
      "Epoch 00005: val_loss improved from 0.18474 to 0.10394, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 22s 543ms/step - loss: 0.0651 - accuracy: 0.9821 - dice_loss: 0.0452 - recall_1: 0.9819 - pre_1: 0.9821 - val_loss: 0.1039 - val_accuracy: 0.9756 - val_dice_loss: 0.0420 - val_recall_1: 0.9756 - val_pre_1: 0.9757 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9841 - dice_loss: 0.0372 - recall_1: 0.9841 - pre_1: 0.9841\n",
      "Epoch 00006: val_loss improved from 0.10394 to 0.06040, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 22s 549ms/step - loss: 0.0545 - accuracy: 0.9841 - dice_loss: 0.0372 - recall_1: 0.9841 - pre_1: 0.9841 - val_loss: 0.0604 - val_accuracy: 0.9820 - val_dice_loss: 0.0386 - val_recall_1: 0.9818 - val_pre_1: 0.9822 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9842 - dice_loss: 0.0335 - recall_1: 0.9842 - pre_1: 0.9841\n",
      "Epoch 00007: val_loss improved from 0.06040 to 0.05692, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 22s 547ms/step - loss: 0.0515 - accuracy: 0.9842 - dice_loss: 0.0335 - recall_1: 0.9842 - pre_1: 0.9841 - val_loss: 0.0569 - val_accuracy: 0.9800 - val_dice_loss: 0.0358 - val_recall_1: 0.9794 - val_pre_1: 0.9806 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9862 - dice_loss: 0.0282 - recall_1: 0.9863 - pre_1: 0.9862\n",
      "Epoch 00008: val_loss improved from 0.05692 to 0.04577, saving model to model-TV-UNet1.h5\n",
      "41/41 [==============================] - 23s 569ms/step - loss: 0.0436 - accuracy: 0.9862 - dice_loss: 0.0282 - recall_1: 0.9863 - pre_1: 0.9862 - val_loss: 0.0458 - val_accuracy: 0.9836 - val_dice_loss: 0.0262 - val_recall_1: 0.9834 - val_pre_1: 0.9838 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9867 - dice_loss: 0.0261 - recall_1: 0.9867 - pre_1: 0.9865\n",
      "Epoch 00009: val_loss did not improve from 0.04577\n",
      "41/41 [==============================] - 22s 533ms/step - loss: 0.0413 - accuracy: 0.9867 - dice_loss: 0.0261 - recall_1: 0.9867 - pre_1: 0.9865 - val_loss: 0.0472 - val_accuracy: 0.9831 - val_dice_loss: 0.0304 - val_recall_1: 0.9829 - val_pre_1: 0.9834 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 0.9879 - dice_loss: 0.0231 - recall_1: 0.9880 - pre_1: 0.9878\n",
      "Epoch 00010: val_loss did not improve from 0.04577\n",
      "41/41 [==============================] - 22s 535ms/step - loss: 0.0366 - accuracy: 0.9879 - dice_loss: 0.0231 - recall_1: 0.9880 - pre_1: 0.9878 - val_loss: 0.0493 - val_accuracy: 0.9808 - val_dice_loss: 0.0312 - val_recall_1: 0.9804 - val_pre_1: 0.9812 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=64, dropout=0.2, batchnorm=True)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=[custom_loss], metrics=['accuracy', dice_loss, Recall(name='recall_1'), Precision(name='pre_1')])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=50, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('model-TV-UNet1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "results = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, callbacks=callbacks, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dce9ac48-b9be-4d11-9ce1-0b1412d213dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 15:39:14.019944: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "## save model as ONNX\n",
    "\n",
    "if not os.path.exists('tf_model'):\n",
    "    os.makedirs('tf_model')\n",
    "\n",
    "if not os.path.exists('onnx_loaded_model'):\n",
    "    os.makedirs('onnx_loaded_model')\n",
    "\n",
    "tf.saved_model.save(model, 'tf_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd6ec2d-eae9-4946-9087-9376e5f75e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5bca0-c0a8-468c-94f3-84f66dda780b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa091d-702e-406a-87e7-41cbd483d3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e48809-0fba-4377-a190-0ce4c77c600f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
